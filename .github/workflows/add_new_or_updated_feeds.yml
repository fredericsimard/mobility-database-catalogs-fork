name: Add new or updated feeds from Google Sheets/Form

on:
  push:
    branches: [ main ]

# on:
#     schedule:
#         - cron: '0 0 * * *' # At 00:00 UTC every day

env:
    CSV_URL: "https://docs.google.com/a/google.com/spreadsheets/d/1Q96KDppKsn2khdrkraZCQ7T_qRSfwj7WsvqXvuMt4Bc/gviz/tq?tq=select%20*&tqx=out:csv"
    
    DATE_FORMAT: "[0-9]{1,2}/[0-9]{1,2}/[0-9]{4}|[0-9]{4}-[0-9]{2}-[0-9]{2}" # this is the format we need to compare dates between the CSV and the local system.
    
    USERNAME: "github-actions[bot]" # GitHub username that will create the PR
    USERNAME_EMAIL: "41898282+github-actions[bot]@users.noreply.github.com"
    
    ORGANIZATION: MobilityData # organization name
    REPO_NAME: mobity-database-catalogs # repository name
    BASE: "main"
    
    REVIEWERS_JSON: "[\"emmambd\"]" # List of GitHub usernames of the reviewers, in a JSON array : ["username1", "username2"]

    GTFS_SCHEDULE_CATALOG_PATH_FROM_ROOT: "catalogs/sources/gtfs/schedule/"
    GTFS_REALTIME_CATALOG_PATH_FROM_ROOT: "catalogs/sources/gtfs/realtime/"

jobs:
  add-new-updated-feeds:
    runs-on: ubuntu-latest
    steps:
      - name: Setup global variables
        id: global_vars
        run: |
            echo "TODAYS_DATE=$(date +%m/%d/%Y)" >> $GITHUB_ENV # Ex.: 07/27/2023
            echo "TODAYS_DAY=$(date '+%d')" >> $GITHUB_ENV # Ex.: 27
            echo "TODAYS_MONTH=$(date '+%m')" >> $GITHUB_ENV # Ex.: 07
            echo "TODAYS_YEAR=$(date '+%Y')" >> $GITHUB_ENV # Ex.: 2023

      - name: Create branch name
        id: create_branch_name
        run: |
            echo "BRANCH=${{ env.TODAYS_YEAR }}-${{ env.TODAYS_MONTH }}-${{ env.TODAYS_DAY }}" >> $GITHUB_OUTPUT # Branch name

      - name: Load secrets from 1Password
        id: onepw_secrets
        uses: 1password/load-secrets-action@v1.3.1
        with:
            export-env: true # Export loaded secrets as environment variables
        env:
            OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
            CREDENTIALS: "op://rbiv7rvkkrsdlpcrz3bmv7nmcu/ifkeehu5gzi7wy5ub5qvwkaire/credential"

      - name: Checkout repo
        id: checkout_repo
        uses: actions/checkout@v4
        with:
            ref: ${{ env.BASE }}
            fetch-depth: 0
            token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }} # ${{ env.CREDENTIALS }} 

      - name: Create new branch
        shell: bash
        run: |
            git checkout -b ${{ steps.create_branch_name.outputs.BRANCH }}
            git reset --hard ${{ env.BASE }}

      - name: Download CSV and process each lines
        id: process-csv
        shell: bash
        run: |
            extract_date() {
                # function to extract a date in the proper format for this script.
                # USAGE : date=$(extract_date "7/5/2023 15:50:58")
                #         echo "Extracted date: $date"
                local text="$1"
                local extracted_date=$(echo "$text" | grep -oE "${{ env.DATE_FORMAT }}" | head -1)
                
                if [[ $extracted_date =~ [0-9]{4}-[0-9]{2}-[0-9]{2} ]]; then
                    # Convert "yyyy-mm-dd" to "mm/dd/yyyy"
                    formatted_date=$(printf "%s" "$extracted_date" | awk -F"-" '{printf "%02d/%02d/%s", $2, $3, $1}')
                else
                    # Convert "m/d/yyyy" to "mm/dd/yyyy"
                    formatted_date=$(printf "%s" "$extracted_date" | awk -F"/" '{printf "%02d/%02d/%s", $1, $2, $3}')
                fi
            
                echo "$formatted_date"
            }

            # Download the CSV data from the Google Sheet
            CSV_DATA=$(curl -sL ${{ env.CSV_URL }})

            # Remove the header row, not needed.
            IFS=$'\n'
            csv_data_no_headers=$(awk 'NR>1' <<< "${CSV_DATA}")
            declare -a csv_lines

            # Filter out the lines that haven't been added in the last 24h
            while IFS= read -r line; do
                extracted_date=$(extract_date "$line")
                if [[ "$extracted_date" == "${{ env.TODAYS_DATE }}" ]]; then
                    csv_lines+=("$line")
                fi
            done <<< "$csv_data_no_headers"

            # Default values for variables
            PYTHON_SCRIPT_ARGS=""

            # Cycle through the lines added in the last 24h
            for line in $csv_lines[@]; do
                IFS=','

                read -ra items_array <<< "$line"

                timestamp="${items_array[0]}"
                provider="${items_array[1]}"
                regioncity="${items_array[2]}"
                currenturl="${items_array[3]}"
                updatednewsourceurl="${items_array[4]}"
                datatype1="${items_array[5]}"
                request="${items_array[6]}"
                downloadurl="${items_array[7]}"
                country="${items_array[8]}"
                subdivision_name="${items_array[9]}"
                municipality="${items_array[10]}"
                name="${items_array[11]}"
                yournameorg="${items_array[12]}"
                license_url="${items_array[13]}"
                tripupdatesurl="${items_array[14]}"
                servicealertsurl="${items_array[15]}"
                genunknownrturl="${items_array[16]}"
                authentication_type="${items_array[17]}"
                authentication_info_url="${items_array[18]}"
                api_key_parameter_name="${items_array[19]}"
                note="${items_array[20]}"
                gtfsschedulefeatures="${items_array[21]}"
                gtfsschedulestatus="${items_array[22]}"
                gtfsrealtimestatus="${items_array[23]}"
                realtimefeatures="${items_array[26]}"

                PYTHON_SCRIPT_ARGS_TEMP=""

                echo -e "FOUND ONE ROW ADDED TODAY: $provider"

                # Create the argument string to send to the Python script
                if [[ $issuetype = "New source" ]]
                then
                    echo -e "   NEW SOURCE"

                    if [[ $datatype1 = *"Schedule"* ]]
                    then # add_gtfs_schedule_source

                        PYTHON_SCRIPT_ARGS_TEMP="add_gtfs_schedule_source(provider=${provider}, country_code=${country}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, subdivision_name=${subdivision_name}, municipality=${municipality}, license_url=${license_url}, name=${name}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})"
                    
                    elif [[ $datatype1 = *"Realtime"* ]]
                    then # add_gtfs_realtime_source
                    
                        # Emma: entity_type matches the realtime Data type options of Vehicle Positions, Trip Updates, or Service Alerts.
                        # If one of those three are selected, add it. If not, omit it.

                        PYTHON_SCRIPT_ARGS_TEMP="add_gtfs_realtime_source(entity_type=${datatype1}, provider=${provider}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, license_url=${license_url}, name=${name}, static_reference=TO_BE_PROVIDED, note=${note}, status=${status2}, features=${features2})"

                        fi

                elif [[ $issuetype = "Source update" ]]
                then
                    echo -e "   SOURCE UPDATE"

                    if [[ $datatype1 = *"Schedule"* ]]
                    then # update_gtfs_schedule_source

                        PYTHON_SCRIPT_ARGS_TEMP="update_gtfs_schedule_source(mdb_source_id=}}, provider=${provider}, name=${name}, country_code=${country}, subdivision_name=${subdivision_name}, municipality=${municipality}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, license_url=${license_url}, status=${status1}, features=${features1})"

                    elif [[ $datatype1 = *"Realtime"* ]]
                    then # update_gtfs_realtime_source

                        PYTHON_SCRIPT_ARGS_TEMP="update_gtfs_realtime_source(mdb_source_id=}}, entity_type=${datatype1}, provider=${provider}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, license_url=${license_url}, name=${name}, static_reference=TO_BE_PROVIDED, note=${note}, status=${status2}, features=${features2})"

                    fi

                elif [[ $issuetype = *"removed"* ]]
                then
                    echo -e "   REMOVING SOURCE"

                    # Emma: It's very rarely selected. In those cases, you could just update the name field of the feed "requested for removal" and I can decide what to do with it manually.

                        if [[ $datatype1 = *"Schedule"* ]]
                        then # update_gtfs_schedule_source

                            PYTHON_SCRIPT_ARGS_TEMP="update_gtfs_schedule_source(mdb_source_id=}}, provider=${provider}, name=}**** Requested for removal ****}, country_code=${country}, subdivision_name=${subdivision_name}, municipality=${municipality}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, license_url=${license_url}, status=${status1}, features=${features1})"

                        elif [[ $datatype1 = *"Realtime"* ]]
                        then # update_gtfs_realtime_source

                            PYTHON_SCRIPT_ARGS_TEMP="update_gtfs_realtime_source(mdb_source_id=}}, entity_type=${datatype1}, provider=${provider}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, license_url=${license_url}, name=}**** Requested for removal ****}, static_reference=TO_BE_PROVIDED, note=${note}, status=${status2}, features=${features2})"

                        fi

                else # ... assume this is a new source by default :: add_gtfs_schedule_source
                    echo -e "   ASSUMING DEFAULT, NEW SOURCE"

                    PYTHON_SCRIPT_ARGS_TEMP="add_gtfs_schedule_source(provider=${provider}, country_code=${country}, direct_download_url=${updatednewsourceurl}, authentication_type=${authentication_type}, authentication_info_url=${authentication_info_url}, api_key_parameter_name=${api_key_parameter_name}, subdivision_name=${subdivision_name}, municipality=${municipality}, license_url=${license_url}, name=${name}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})"

                fi

                echo "PYTHON_SCRIPT_ARGS_TEMP : ${PYTHON_SCRIPT_ARGS_TEMP}"

                PYTHON_SCRIPT_ARGS="${PYTHON_SCRIPT_ARGS}${PYTHON_SCRIPT_ARGS_TEMP}/n"

            done # end loop

            # Remove the extra newline at the end using sed
            PYTHON_SCRIPT_ARGS=$(echo -e "$PYTHON_SCRIPT_ARGS" | sed '$ d')

            echo "PYTHON_SCRIPT_ARGS : ${PYTHON_SCRIPT_ARGS}"

            echo "PYTHON_SCRIPT_ARGS=${PYTHON_SCRIPT_ARGS}" >> $GITHUB_OUTPUT

      - name: Setup Python
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        uses: actions/setup-python@v4.7.0
        with:
          python-version: '3.11' # install the python version needed

      - name: Create + activate a Python virtual env & Run the script
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        env:
          PYTHONPATH: ${{ github.workspace }}/tools
          PYTHONIOENCODING: "utf8" #ascii
        shell: bash
        run: |
            echo "ARGS: ${{ steps.process-csv.outputs.PYTHON_SCRIPT_ARGS }}"
            python -m venv env
            source env/bin/activate
            pip install virtualenv --quiet
            pip install gtfs_kit --quiet
            pip install unidecode --quiet
            echo "PYTHONPATH=${PYTHONPATH}"
            echo "PYTHONIOENCODING=${PYTHONIOENCODING}"
            IFS=$'\n'
            while IFS= read -r line; do
                python -c 'from tools.operations import *; ${line}'
            done <<< "${{ steps.process-csv.outputs.PYTHON_SCRIPT_ARGS }}"

      - name: Commit & push
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        uses: EndBug/add-and-commit@v9.1.3
        with:
            github_token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }}
            new_branch: ${{ steps.create_branch_name.outputs.BRANCH }}
            author_name: ${{ env.USERNAME }}
            author_email: ${{ env.USERNAME_EMAIL }}
            committer_name: ${{ env.USERNAME }}
            committer_email: ${{ env.USERNAME_EMAIL }}
            message: "Automated commit â€” New/Updated feed"

    #   - name: Create Pull Request
    #     if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
    #     uses: peter-evans/create-pull-request@v5.0.2
    #     with:
    #         token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }} # ${{ env.CREDENTIALS }}
    #         title: "new JSON"
    #         commit-message: "New JSON"
    #         body: "body"
    #         author: "${{ env.USERNAME }} <${{ env.USERNAME_EMAIL }}>"
    #         reviewers: ${{ env.REVIEWERS_JSON }}
    #         branch: ${{ steps.create_branch_name.outputs.BRANCH }}
    #         base: ${{ env.BASE }}
    #         add-paths: |
    #             ${{ env.GTFS_SCHEDULE_CATALOG_PATH_FROM_ROOT }}
    #             ${{ env.GTFS_REALTIME_CATALOG_PATH_FROM_ROOT }}