name: Add new or updated feeds from Google Sheets/Form

on:
  push:
    branches: [ main ]

# on:
#     schedule:
#         - cron: '0 0 * * *' # At 00:00 UTC every day

env:
    CSV_URL: "https://docs.google.com/a/google.com/spreadsheets/d/1Q96KDppKsn2khdrkraZCQ7T_qRSfwj7WsvqXvuMt4Bc/gviz/tq?tq=select%20*&tqx=out:csv"
    
    DATE_FORMAT: "[0-9]{1,2}/[0-9]{1,2}/[0-9]{4}|[0-9]{4}-[0-9]{2}-[0-9]{2}" # this is the format we need to compare dates between the CSV and the local system.
    
    USERNAME: "github-actions[bot]" # GitHub username that will create the PR
    USERNAME_EMAIL: "41898282+github-actions[bot]@users.noreply.github.com"
    
    ORGANIZATION: MobilityData # organization name
    REPO_NAME: mobity-database-catalogs # repository name
    BASE: "main"
    
    REVIEWERS_JSON: "[\"emmambd\"]" # List of GitHub usernames of the reviewers, in a JSON array : ["username1", "username2"]

    GTFS_SCHEDULE_CATALOG_PATH_FROM_ROOT: "catalogs/sources/gtfs/schedule/"
    GTFS_REALTIME_CATALOG_PATH_FROM_ROOT: "catalogs/sources/gtfs/realtime/"

jobs:
  add-new-updated-feeds:
    runs-on: ubuntu-latest
    steps:
      - name: Setup global variables
        id: global_vars
        run: |
            echo "TODAYS_DATE=$(date +%m/%d/%Y)" >> $GITHUB_ENV # Ex.: 07/27/2023
            echo "TODAYS_DAY=$(date '+%d')" >> $GITHUB_ENV # Ex.: 27
            echo "TODAYS_MONTH=$(date '+%m')" >> $GITHUB_ENV # Ex.: 07
            echo "TODAYS_YEAR=$(date '+%Y')" >> $GITHUB_ENV # Ex.: 2023

      - name: Create branch name
        id: create_branch_name
        run: |
            echo "BRANCH=${{ env.TODAYS_YEAR }}-${{ env.TODAYS_MONTH }}-${{ env.TODAYS_DAY }}" >> $GITHUB_OUTPUT # Branch name

      - name: Load secrets from 1Password
        id: onepw_secrets
        uses: 1password/load-secrets-action@v1.3.1
        with:
            export-env: true # Export loaded secrets as environment variables
        env:
            OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
            CREDENTIALS: "op://rbiv7rvkkrsdlpcrz3bmv7nmcu/ifkeehu5gzi7wy5ub5qvwkaire/credential"

      - name: Checkout repo
        id: checkout_repo
        uses: actions/checkout@v4
        with:
            ref: ${{ env.BASE }}
            fetch-depth: 0
            token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }} # ${{ env.CREDENTIALS }} 

      - name: Create new branch
        shell: bash
        run: |
            git checkout -b ${{ steps.create_branch_name.outputs.BRANCH }}
            git reset --hard ${{ env.BASE }}

      - name: Use Node.js 16.x
        uses: actions/setup-node@v3.8.1
        with:
          node-version: '16.x'

      - name: Install Node.js dependencies
        shell: bash
        run: npm install @actions/github

      - name: Setup Javascript
        shell: bash
        run: npm install node-fetch

      - name: Download CSV and process each lines
        id: process-csv
        uses: actions/github-script@v6
        with:
            script: |
                const nodeFetch = require('node-fetch');
                
                function extractDate(text, dateFormat) {
                    // Function to extract a date in the proper format for this script.
                    // USAGE: const date = extractDate("7/5/2023 15:50:58", process.env.DATE_FORMAT);
                
                    const extractedDate = text.match(new RegExp("${{ env.DATE_FORMAT }}"))[0];
                
                    if (/^\d{4}-\d{2}-\d{2}$/.test(extractedDate)) {
                        // Convert "yyyy-mm-dd" to "mm/dd/yyyy"
                        const parts = extractedDate.split('-');
                        const formattedDate = `${parts[1]}/${parts[2]}/${parts[0]}`;
                        return formattedDate;
                    } else {
                        // Convert "m/d/yyyy" to "mm/dd/yyyy"
                        const parts = extractedDate.split('/');
                        const formattedDate = `${parts[0].padStart(2, '0')}/${parts[1].padStart(2, '0')}/${parts[2]}`;
                        return formattedDate;
                    }
                }
                
                const url = ${{ env.CSV_URL }};
                    
                try {
                    const response = nodeFetch(url);
                    
                    if (!response.ok) {
                        throw new Error(`Failed to fetch CSV data: ${response.status} ${response.statusText}`);
                    }
                
                    const csvData = response.text();
                
                    // Split CSV data into lines and remove the header row
                    const csvLines = csvData.trim().split('\n').slice(1);
                
                    // Get the current date in the same format as extracted_date
                    const currentDate = new Date().toLocaleDateString('en-US', { year: 'numeric', month: '2-digit', day: '2-digit' });
                    console.log('currentDate : ' + currentDate)
                
                    // Filter out lines added in the last 24 hours
                    const filteredLines = csvLines.filter((line) => {
                        const extractedDate = extractDate(line, "${{ env.DATE_FORMAT }}");
                        return extractedDate === currentDate;
                    });
                
                    // Initialize variable
                    let PYTHON_SCRIPT_ARGS = "";
                
                    for (const curLine of filteredLines) {
                        const itemsArray = curLine.split(',');
                        console.log("current cur_line : " + itemsArray);
                    
                        const [
                            timestamp,
                            provider,
                            regionCity,
                            currentUrl,
                            updatedNewSourceUrl,
                            datatype1,
                            request,
                            downloadUrl,
                            country,
                            subdivisionName,
                            municipality,
                            name,
                            yourNameOrg,
                            licenseUrl,
                            tripUpdatesUrl,
                            serviceAlertsUrl,
                            genUnknownRtUrl,
                            authenticationType,
                            authenticationInfoUrl,
                            apiKeyParameterName,
                            note,
                            gtfsschedulefeatures,
                            gtfsschedulestatus,
                            gtfsrealtimestatus,
                            yourEmail,
                            dataProducerEmail,
                            realtimeFeatures,
                            ISOalphaCountryCode,
                            feedUpdateStatus
                        ] = itemsArray;
                
                        let PYTHON_SCRIPT_ARGS_TEMP = "";
                
                        if (request === "New source") {
                            console.log('   NEW SOURCE')
                
                            if (datatype1.includes("Schedule")) {
                                
                                PYTHON_SCRIPT_ARGS_TEMP = `add_gtfs_schedule_source(provider=${provider}, country_code=${country}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, subdivision_name=${subdivisionName}, municipality=${municipality}, license_url=${licenseUrl}, name=${name}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})`;
                            
                            } else if (datatype1.includes("Realtime")) {
                                // Emma: entity_type matches the realtime Data type options of Vehicle Positions, Trip Updates, or Service Alerts.
                                // If one of those three is selected, add it. If not, omit it.
                                const entityType = ["Vehicle Positions", "Trip Updates", "Service Alerts"].includes(datatype1) ? datatype1 : '';
                
                                PYTHON_SCRIPT_ARGS_TEMP = `add_gtfs_realtime_source(entity_type=${entityType}, provider=${provider}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, license_url=${licenseUrl}, name=${name}, static_reference=TO_BE_PROVIDED, note=${note}, status=${gtfsrealtimestatus}, features=${realtimeFeatures})`;
                            }
                
                        } else if (request === "Source update") {
                            console.log('   SOURCE UPDATE')
                            
                            if (datatype1.includes("Schedule")) {
                                
                                PYTHON_SCRIPT_ARGS_TEMP = `update_gtfs_schedule_source(mdb_source_id=, provider=${provider}, name=${name}, country_code=${country}, subdivision_name=${subdivisionName}, municipality=${municipality}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, license_url=${licenseUrl}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})`;
                
                            } else if (datatype1.includes("Realtime")) {
                                
                                PYTHON_SCRIPT_ARGS_TEMP = `update_gtfs_realtime_source(mdb_source_id=, entity_type=${datatype1}, provider=${provider}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, license_url=${licenseUrl}, name=${name}, static_reference=TO_BE_PROVIDED, note=${note}, status=${gtfsrealtimestatus}, features=${realtimeFeatures})`;
                
                            }
                
                        } else if (request.includes("removed")) {
                            // Emma: It's very rarely selected. In those cases, you could just update the name field of the feed "requested for removal" and I can decide what to do with it manually.
                
                            console.log('   REMOVAL')
                
                            if (datatype1.includes("Schedule")) {
                                
                                PYTHON_SCRIPT_ARGS_TEMP = `update_gtfs_schedule_source(mdb_source_id=, provider=${provider}, name="**** Requested for removal ****", country_code=${country}, subdivision_name=${subdivisionName}, municipality=${municipality}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, license_url=${licenseUrl}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})`;
                
                            } else if (datatype1.includes("Realtime")) {
                
                                PYTHON_SCRIPT_ARGS_TEMP = `update_gtfs_realtime_source(mdb_source_id=, entity_type=${datatype1}, provider=${provider}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, license_url=${licenseUrl}, name="**** Requested for removal ****", static_reference=TO_BE_PROVIDED, note=${note}, status=${gtfsrealtimestatus}, features=${realtimeFeatures})`;
                
                            }
                
                        } else { // ... assume this is a new source by default :: add_gtfs_schedule_source
                            console.log('   ASSUMING DEFAULT, NEW SOURCE')
                
                            PYTHON_SCRIPT_ARGS_TEMP = `add_gtfs_schedule_source(provider=${provider}, country_code=${country}, direct_download_url=${updatedNewSourceUrl}, authentication_type=${authenticationType}, authentication_info_url=${authenticationInfoUrl}, api_key_parameter_name=${apiKeyParameterName}, subdivision_name=${subdivisionName}, municipality=${municipality}, license_url=${licenseUrl}, name=${name}, status=${gtfsschedulestatus}, features=${gtfsschedulefeatures})`;
                            
                        }
                
                        PYTHON_SCRIPT_ARGS += `\n${PYTHON_SCRIPT_ARGS_TEMP}`;
                
                    } // end for loop
                
                    // Remove the extra newline at the end
                    PYTHON_SCRIPT_ARGS = PYTHON_SCRIPT_ARGS.trim();
                    console.log('PYTHON_SCRIPT_ARGS : ' + PYTHON_SCRIPT_ARGS)
                
                    core.setOutput('PYTHON_SCRIPT_ARGS', PYTHON_SCRIPT_ARGS);
                
                } catch (error) {
                    console.error('Error:' + error.message);
                }

      - name: Setup Python
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        uses: actions/setup-python@v4.7.0
        with:
          python-version: '3.11' # install the python version needed

      - name: Create + activate a Python virtual env & Run the script
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        env:
          PYTHONPATH: ${{ github.workspace }}/tools
          PYTHONIOENCODING: "utf8" #ascii
        shell: bash
        run: |
            echo "ARGS: ${{ steps.process-csv.outputs.PYTHON_SCRIPT_ARGS }}"
            python -m venv env
            source env/bin/activate
            pip install virtualenv --quiet
            pip install gtfs_kit --quiet
            pip install unidecode --quiet
            echo "PYTHONPATH=${PYTHONPATH}"
            echo "PYTHONIOENCODING=${PYTHONIOENCODING}"
            IFS=$'\n'
            while IFS= read -r current_line; do
                python -c 'from tools.operations import *; ${current_line}'
            done <<< "${{ steps.process-csv.outputs.PYTHON_SCRIPT_ARGS }}"

      - name: Commit & push
        if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
        uses: EndBug/add-and-commit@v9.1.3
        with:
            github_token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }}
            new_branch: ${{ steps.create_branch_name.outputs.BRANCH }}
            author_name: ${{ env.USERNAME }}
            author_email: ${{ env.USERNAME_EMAIL }}
            committer_name: ${{ env.USERNAME }}
            committer_email: ${{ env.USERNAME_EMAIL }}
            message: "Automated commit â€” New/Updated feed"

    #   - name: Create Pull Request
    #     if: steps.process-csv.outputs.PYTHON_SCRIPT_ARGS != ''
    #     uses: peter-evans/create-pull-request@v5.0.2
    #     with:
    #         token: ${{ secrets.FRED_PERSONAL_GITHUB_TOKEN }} # ${{ env.CREDENTIALS }}
    #         title: "new JSON"
    #         commit-message: "New JSON"
    #         body: "body"
    #         author: "${{ env.USERNAME }} <${{ env.USERNAME_EMAIL }}>"
    #         reviewers: ${{ env.REVIEWERS_JSON }}
    #         branch: ${{ steps.create_branch_name.outputs.BRANCH }}
    #         base: ${{ env.BASE }}
    #         add-paths: |
    #             ${{ env.GTFS_SCHEDULE_CATALOG_PATH_FROM_ROOT }}
    #             ${{ env.GTFS_REALTIME_CATALOG_PATH_FROM_ROOT }}